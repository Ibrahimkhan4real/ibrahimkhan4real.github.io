---
layout: default
title: "AI Demos â€” Muhammad Ibrahim Khan"
---

<header>
  <p>Interactive Reinforcement Learning</p>
</header>

<article>
  <div id="article_title">
    <h1>Interactive AI Demos</h1>
  </div>
  <div id="article_text">
    <p class="lead">Research is better when you can see it in action. Below are browser-based visualizations of the algorithms I use in my PhD.</p>

    <section class="status-section">
      <h2>MCTS: Decision Tree Visualization</h2>
      <p>Watch <strong>Monte Carlo Tree Search</strong> build a decision tree step by step. Each iteration cycles through four phases: <strong>Selection</strong> (traverse the tree using UCB1), <strong>Expansion</strong> (arrive at a new node), <strong>Simulation</strong> (random rollout to a leaf), and <strong>Backpropagation</strong> (update visit counts and reward estimates up the path).</p>

      <div id="mcts-container" style="width: 100%; height: 400px; border: 1px solid var(--border); border-radius: 8px; background: var(--panel); position: relative; overflow: hidden;">
        <canvas id="mcts-canvas" role="img" aria-label="MCTS decision tree visualization showing selection, expansion, simulation, and backpropagation phases"></canvas>
        <div id="mcts-controls" style="position: absolute; bottom: 10px; left: 10px; display: flex; gap: 10px;">
          <button class="button_accent" id="mcts-step">Step</button>
          <button class="button_accent" id="mcts-reset">Reset</button>
        </div>
      </div>
      <div class="demo-stats" id="mcts-info"></div>
      <p class="travel-note">Internal nodes show visit count (top) and average reward (bottom). Leaf nodes show their reward value. Node colour intensity reflects how often a node has been visited. The algorithm uses UCB1 (C=&radic;2) to balance exploration and exploitation.</p>
    </section>

    <section class="status-section">
      <h2>Q-Learning Grid World</h2>
      <p>Watch a <strong>Q-learning</strong> agent learn the optimal policy in an 8&times;8 grid. Click cells to toggle walls, shift-click or right-click to set the goal. Arrow direction shows the best action; color intensity shows Q-value magnitude.</p>

      <div id="ql-container" class="demo-container">
        <canvas id="ql-canvas" role="img" aria-label="Q-learning grid world showing agent policy arrows and Q-value intensities"></canvas>
        <div class="demo-controls">
          <button class="button_accent" id="ql-train1">Train 1 Episode</button>
          <button class="button_accent" id="ql-train100">Train 100 Episodes</button>
          <button class="button_accent" id="ql-reset">Reset</button>
        </div>
        <div class="demo-stats" id="ql-stats"></div>
      </div>
      <p class="travel-note">S = start (top-left), G = goal (bottom-right by default). Grey cells are walls. The agent uses &epsilon;-greedy exploration with decay (&alpha;=0.1, &gamma;=0.95).</p>
    </section>

    <section class="status-section">
      <h2>MCTS vs Greedy Comparison</h2>
      <p>Compare <strong>Monte Carlo Tree Search</strong> (UCB1 selection + random rollouts) against a <strong>Greedy</strong> strategy on the same random decision tree. MCTS explores broadly while Greedy commits early.</p>

      <div class="demo-side-by-side">
        <div class="demo-panel" id="mvg-mcts-panel">
          <div class="demo-panel-title">MCTS (UCB1)</div>
          <canvas id="mvg-mcts-canvas" role="img" aria-label="MCTS algorithm decision tree with visit counts and selected path"></canvas>
        </div>
        <div class="demo-panel" id="mvg-greedy-panel">
          <div class="demo-panel-title">Greedy</div>
          <canvas id="mvg-greedy-canvas" role="img" aria-label="Greedy algorithm decision tree with selected path"></canvas>
        </div>
      </div>
      <div class="demo-container" style="border-top: none; border-radius: 0 0 8px 8px; margin-top: -1px;">
        <div class="demo-controls">
          <button class="button_accent" id="mvg-generate">New Tree</button>
          <button class="button_accent" id="mvg-run">Run Comparison</button>
          <button class="button_accent" id="mvg-step">Step</button>
          <label class="demo-slider-label">Speed
            <input type="range" class="demo-slider" id="mvg-speed" min="1" max="100" value="50">
          </label>
        </div>
        <div class="demo-stats" id="mvg-stats"></div>
      </div>
      <p class="travel-note">Leaf nodes show reward values. Node numbers show visit counts (MCTS). Highlighted paths show the final chosen route. MCTS uses C=&radic;2 for exploration.</p>
    </section>

    <section class="status-section">
      <h2>Multi-Armed Bandit Playground</h2>
      <p>Explore the <strong>exploration vs exploitation</strong> dilemma. Each arm is a slot machine with a hidden reward probability. Click an arm to pull it manually, or use an automated strategy.</p>

      <div id="bandit-container" class="demo-container">
        <canvas id="bandit-canvas" role="img" aria-label="Multi-armed bandit bar chart showing estimated reward per arm"></canvas>
        <canvas id="bandit-regret-canvas" role="img" aria-label="Cumulative regret line chart over time for the bandit strategy"></canvas>
        <div class="demo-controls">
          <select class="demo-select" id="bandit-strategy">
            <option value="epsilon">&epsilon;-Greedy (&epsilon;=0.1)</option>
            <option value="ucb1">UCB1</option>
          </select>
          <button class="button_accent" id="bandit-auto">Auto Run 100</button>
          <button class="button_accent" id="bandit-reset">Reset</button>
        </div>
        <div class="demo-stats" id="bandit-stats"></div>
      </div>
      <p class="travel-note">Click directly on an arm bar to pull it manually. The bar chart shows estimated reward per arm; the line chart tracks cumulative regret over time. Each arm is a Bernoulli bandit with fixed hidden probability.</p>
    </section>
  </div>
</article>

<script src="{{ "/assets/js/mcts-demo.js" | relative_url }}"></script>
<script src="{{ "/assets/js/qlearning-demo.js" | relative_url }}"></script>
<script src="{{ "/assets/js/mcts-vs-greedy-demo.js" | relative_url }}"></script>
<script src="{{ "/assets/js/bandit-demo.js" | relative_url }}"></script>
